{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 两个反爬机制：\n",
    "- robots.txt-\n",
    "- UA检测\n",
    "- 指定 url\n",
    "- 发起请求\n",
    "- 获取页面数据\n",
    "- 数据解析\n",
    "- 持久化存储\n",
    "### bs4 \n",
    "- 实例化 ， 将页面源码数据 加载到该对象中\n",
    "- 定位标签 \n",
    "-   find , find_all(['a','div']) , select()\n",
    "- 获取标签中的文本内容  \n",
    "-   obj.string, obj.text, obj.get_text()\n",
    "\n",
    "### xpath\n",
    "- envi pip install lxml\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over\n"
     ]
    }
   ],
   "source": [
    "## 解析 58  二手房的相关数据\n",
    "from lxml import etree\n",
    "import requests\n",
    "url = 'https://cc.58.com/ershoufang/?PGTID=0d200001-0013-f54c-3de5-0b080fe23885&ClickID=1'\n",
    "header = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; rv:66.0) Gecko/20100101 Firefox/66.0',\n",
    "}\n",
    "pg_text = requests.get(url=url,headers=header).text\n",
    "tree = etree.HTML(pg_text)           # return  <Element html at 0x7351a08>\n",
    "li_list = tree.xpath('//ul[@class=\"house-list-wrap\"]/li')   # return <class 'list'>\n",
    "##  li_list[0]  #  return <Element li at 0x7341490>;  type---><class 'lxml.etree._Element'>\n",
    "f = open(\"58.csv\",'w',encoding='utf-8')\n",
    "for li in li_list:\n",
    "    title = li.xpath('./div[2]/h2/a/text()')[0]  # 获取下标 为 零 的文本 \n",
    "    price = li.xpath('./div[3]//text()')         # 此 div 下的 所有文本内容\n",
    "    price = ''.join(price)\n",
    "    info = li.xpath('./div[2]/p//text()')   \n",
    "    info = ''.join(info)\n",
    "    f.write(title+':'+price+'-->'+info+'\\n')\n",
    "f.close()\n",
    "print('over')\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 解析彼岸图网的图片\n",
    "import requests\n",
    "from lxml import etree\n",
    "import urllib\n",
    "import os\n",
    "\n",
    "url = 'http://pic.netbian.com/4kmeinv/'\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; rv:66.0) Gecko/20100101 Firefox/66.0',\n",
    "}\n",
    "response = requests.get(url=url,headers=headers)\n",
    "# response.encoding = 'utf-8'                                # 通常解决乱码问题的解决方案\n",
    "pg_text = response.text\n",
    "\n",
    "if not os.path.exists('./biantu'):                          # 创建文件夹\n",
    "    os.mkdir('./biantu')\n",
    "tree = etree.HTML(pg_text)\n",
    "li_list = tree.xpath('//div[@class=\"slist\"]/ul/li')\n",
    "for s in li_list:\n",
    "    img_name = s.xpath('./a/b/text()')[0]                    # xpath 获得的数据为一个 列表，\n",
    "    img_name = img_name.encode('iso-8859-1').decode('gbk')   ### 万能的解决中文 乱码问题的方案 *******\n",
    "    img_url ='http://pic.netbian.com'+s.xpath('./a/img/@src')[0]\n",
    "    img_path = './biantu/' + img_name + '.jpg'\n",
    "#     img = requests.get(url=img_url,headers=headers).content\n",
    "    urllib.request.urlretrieve(url=img_url,filename=img_path)\n",
    "    print(img_name + \"下载成功！\")\n",
    "print('over')\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
